{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this lesson, you've been trying different models on the same two datasets, wine and diabetes. Now, we're going to try our hand at accelerating this methodology by using AutoGluon. In this exercise, train two different AutonGluon models and see how they compare to previous iterations in exercise 1 and 2.\n",
    "\n",
    "You're tasked with completing the following steps:\n",
    "1. Load in the wine dataset from scikit learn.\n",
    "2. For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "3. Create a AutoGluon Classifier model with these hyper parameters:\n",
    "    1. time_limit: 120\n",
    "    2. presets: best_quality\n",
    "4. Output the model table summary\n",
    "5. Evaluate the trained model on the test dataset\n",
    "6. Load the diabetes dataset from scikit learn\n",
    "7. For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "8. Create a AutoGluon Regression model with these hyper parameters:\n",
    "    1. eval_metric: r2\n",
    "    2. time_limit: 120\n",
    "    3. presets: best_quality\n",
    "9. Output the model table summary\n",
    "10. Evaluate the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (21.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
      "     |████████████████████████████████| 2.1 MB 17.9 MB/s            \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.3.1\n",
      "    Uninstalling pip-21.3.1:\n",
      "      Successfully uninstalled pip-21.3.1\n",
      "Successfully installed pip-22.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (59.4.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-63.2.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.4.0\n",
      "    Uninstalling setuptools-59.4.0:\n",
      "      Successfully uninstalled setuptools-59.4.0\n",
      "Successfully installed setuptools-63.2.0 wheel-0.37.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mxnet<2.0.0\n",
      "  Using cached mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
      "Collecting bokeh==2.0.1\n",
      "  Using cached bokeh-2.0.1.tar.gz (8.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (2.8.2)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (1.19.1)\n",
      "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (8.4.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (21.3)\n",
      "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (6.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /usr/local/lib/python3.7/site-packages (from bokeh==2.0.1) (4.0.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/site-packages (from mxnet<2.0.0) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/site-packages (from mxnet<2.0.0) (2.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging>=16.8->bokeh==2.0.1) (3.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->bokeh==2.0.1) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=d2752b80abc3e1708e634be0f82600ed144c9078d40f8f9a180157d01b6a1928\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/9e/ac/f24f30e119df73511fde9af8aa747217ac8824e662037ba9a8\n",
      "Successfully built bokeh\n",
      "Installing collected packages: mxnet, bokeh\n",
      "  Attempting uninstall: bokeh\n",
      "    Found existing installation: bokeh 2.4.2\n",
      "    Uninstalling bokeh-2.4.2:\n",
      "      Successfully uninstalled bokeh-2.4.2\n",
      "Successfully installed bokeh-2.0.1 mxnet-1.9.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting autogluon\n",
      "  Downloading autogluon-0.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting autogluon.tabular[all]==0.5.0\n",
      "  Downloading autogluon.tabular-0.5.0-py3-none-any.whl (272 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.6/272.6 kB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.features==0.5.0\n",
      "  Downloading autogluon.features-0.5.0-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m182.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.core[all]==0.5.0\n",
      "  Downloading autogluon.core-0.5.0-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.1/203.1 kB\u001b[0m \u001b[31m236.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.timeseries[all]==0.5.0\n",
      "  Downloading autogluon.timeseries-0.5.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.text==0.5.0\n",
      "  Downloading autogluon.text-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m183.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.multimodal==0.5.0\n",
      "  Downloading autogluon.multimodal-0.5.0-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 kB\u001b[0m \u001b[31m207.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.vision==0.5.0\n",
      "  Downloading autogluon.vision-0.5.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m168.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas!=1.4.0,<1.5,>=1.2.5 in /usr/local/lib/python3.7/site-packages (from autogluon.core[all]==0.5.0->autogluon) (1.3.4)\n",
      "Requirement already satisfied: scikit-learn<1.1,>=1.0.0 in /usr/local/lib/python3.7/site-packages (from autogluon.core[all]==0.5.0->autogluon) (1.0.1)\n",
      "Collecting numpy<1.23,>=1.21\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/site-packages (from autogluon.core[all]==0.5.0->autogluon) (4.39.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (from autogluon.core[all]==0.5.0->autogluon) (1.20.17)\n",
      "Collecting scipy<1.8.0,>=1.5.4\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting distributed<=2021.11.2,>=2021.09.1\n",
      "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m233.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from autogluon.core[all]==0.5.0->autogluon) (2.22.0)\n",
      "Collecting autogluon.common==0.5.0\n",
      "  Downloading autogluon.common-0.5.0-py3-none-any.whl (37 kB)\n",
      "Collecting dask<=2021.11.2,>=2021.09.1\n",
      "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m238.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (from autogluon.core[all]==0.5.0->autogluon) (3.5.0)\n",
      "Collecting ray<1.14,>=1.13\n",
      "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 MB\u001b[0m \u001b[31m142.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting hyperopt<0.2.8,>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m249.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.7/site-packages (from autogluon.features==0.5.0->autogluon) (5.8.0)\n",
      "Collecting torchmetrics<0.8.0,>=0.7.2\n",
      "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.2/398.2 kB\u001b[0m \u001b[31m244.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting timm<0.6.0\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Pillow<9.1.0,>=9.0.1\n",
      "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m179.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.18.1\n",
      "  Downloading protobuf-3.18.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m247.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nltk<4.0.0,>=3.4.5\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m230.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning<1.7.0,>=1.5.10\n",
      "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 kB\u001b[0m \u001b[31m240.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.2.0,>=2.1.1\n",
      "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m169.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20220208\n",
      "  Downloading autogluon_contrib_nlp-0.0.1b20220208-py3-none-any.whl (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m228.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nlpaug<2.0.0,>=1.1.10\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m184.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fairscale<0.5.0,>=0.4.5\n",
      "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1\n",
      "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m155.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open<5.3.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m179.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m243.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-metric-learning<1.4.0,>=1.3.0\n",
      "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m196.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.21.0,>=4.18.0\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m218.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch<1.12,>=1.0\n",
      "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m156.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nptyping<1.5.0,>=1.4.4\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/site-packages (from autogluon.tabular[all]==0.5.0->autogluon) (2.6.3)\n",
      "Collecting lightgbm<3.4,>=3.3\n",
      "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m226.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xgboost<1.5,>=1.4\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastai<2.6,>=2.3.1\n",
      "  Downloading fastai-2.5.6-py3-none-any.whl (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 kB\u001b[0m \u001b[31m215.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting catboost<1.1,>=1.0\n",
      "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gluonts>=0.8.0\n",
      "  Downloading gluonts-0.10.2-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m236.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sktime~=0.12\n",
      "  Downloading sktime-0.13.0-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pmdarima~=1.8\n",
      "  Downloading pmdarima-1.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m240.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tbats~=1.1\n",
      "  Downloading tbats-1.1.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gluoncv<0.10.6,>=0.10.5\n",
      "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses>=0.0.38\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m257.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20220208->autogluon.multimodal==0.5.0->autogluon) (6.0.1)\n",
      "Collecting tokenizers>=0.9.4\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m248.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m203.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contextvars\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting flake8\n",
      "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2022.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.7/749.7 kB\u001b[0m \u001b[31m228.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yacs>=0.1.6\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "\u001b[33mWARNING: autogluon-core 0.5.0 does not provide the extra 'ray-tune'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: plotly in /usr/local/lib/python3.7/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.0->autogluon) (5.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.0->autogluon) (1.16.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/site-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.0->autogluon) (0.8.4)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (2.0.0)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m157.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (21.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (2021.11.1)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (63.2.0)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.8/299.8 kB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zict>=0.1.3\n",
      "  Downloading zict-2.2.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (3.0.3)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting click>=6.6\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m189.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastcore<1.5,>=1.3.27\n",
      "  Downloading fastcore-1.4.5-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision>=0.8.2\n",
      "  Downloading torchvision-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy<4\n",
      "  Downloading spacy-3.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m195.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (from fastai<2.6,>=2.3.1->autogluon.tabular[all]==0.5.0->autogluon) (22.1.2)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.2-py3-none-any.whl (12 kB)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.0->autogluon) (2.3.2)\n",
      "Collecting autocfg\n",
      "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.5.0->autogluon) (4.5.4.60)\n",
      "Collecting pydantic~=1.7\n",
      "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m166.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting holidays>=0.9\n",
      "  Downloading holidays-0.14.2-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m220.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.7/site-packages (from gluonts>=0.8.0->autogluon.timeseries[all]==0.5.0->autogluon) (4.0.1)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m251.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.5.0->autogluon) (0.37.1)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.5.0->autogluon) (6.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.5.0->autogluon) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.5.0->autogluon) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.5.0->autogluon) (4.28.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.5.0->autogluon) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.5.0->autogluon) (3.0.6)\n",
      "Collecting gdown>=4.0.0\n",
      "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.5.0->autogluon) (1.1.0)\n",
      "Collecting typish>=1.7.0\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m149.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m210.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas!=1.4.0,<1.5,>=1.2.5->autogluon.core[all]==0.5.0->autogluon) (2021.3)\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/site-packages (from pmdarima~=1.8->autogluon.timeseries[all]==0.5.0->autogluon) (0.29.24)\n",
      "Collecting statsmodels!=0.12.0,>=0.11\n",
      "  Downloading statsmodels-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/site-packages (from pmdarima~=1.8->autogluon.timeseries[all]==0.5.0->autogluon) (1.25.11)\n",
      "Collecting tqdm>=4.38.0\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m195.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m142.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.7.2-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m199.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.0->autogluon) (21.2.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting grpcio<=1.43.0,>=1.28.1\n",
      "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m162.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m219.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting virtualenv\n",
      "  Downloading virtualenv-20.15.1-py2.py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m154.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click>=6.6\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m190.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m211.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/site-packages (from ray<1.14,>=1.13->autogluon.core[all]==0.5.0->autogluon) (0.8.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.5.0->autogluon) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.5.0->autogluon) (2021.10.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.5.0->autogluon) (3.0.4)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m147.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.5.0->autogluon) (2.13.1)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m221.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core[all]==0.5.0->autogluon) (3.0.0)\n",
      "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.7/site-packages (from sktime~=0.12->autogluon.timeseries[all]==0.5.0->autogluon) (0.53.1)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from transformers<4.21.0,>=4.18.0->autogluon.multimodal==0.5.0->autogluon) (4.8.2)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m185.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.5.0->autogluon) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.17 in /usr/local/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.5.0->autogluon) (1.23.17)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.5.0->autogluon) (0.10.0)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m189.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m232.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting korean-lunar-calendar\n",
      "  Downloading korean_lunar_calendar-0.2.1-py3-none-any.whl (8.0 kB)\n",
      "Collecting hijri-converter\n",
      "  Downloading hijri_converter-2.2.4-py3-none-any.whl (14 kB)\n",
      "Collecting convertdate>=2.3.0\n",
      "  Downloading convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m167.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/site-packages (from numba>=0.53->sktime~=0.12->autogluon.timeseries[all]==0.5.0->autogluon) (0.36.0)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib->autogluon.core[all]==0.5.0->autogluon) (1.2.2)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1\n",
      "  Downloading wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m196.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m208.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.1/457.1 kB\u001b[0m \u001b[31m240.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (821 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.9/821.9 kB\u001b[0m \u001b[31m247.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.7/233.7 kB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.5.10->autogluon.multimodal==0.5.0->autogluon) (2.0.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m249.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m166.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m191.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m210.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m234.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision>=0.8.2\n",
      "  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.18-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 kB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting pyflakes<2.5.0,>=2.4.0\n",
      "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m191.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
      "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m147.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->transformers<4.21.0,>=4.18.0->autogluon.multimodal==0.5.0->autogluon) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/site-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.5.0->autogluon) (2.0.1)\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.18.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m212.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/site-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.5.0->autogluon) (8.0.1)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20220208->autogluon.multimodal==0.5.0->autogluon) (0.4.3)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.5-py2.py3-none-any.whl (466 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.0/467.0 kB\u001b[0m \u001b[31m243.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
      "Collecting pymeeus<=1,>=0.3.13\n",
      "  Downloading PyMeeus-0.5.11.tar.gz (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m184.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m214.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.5.10->autogluon.multimodal==0.5.0->autogluon) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m197.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m208.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.8/271.8 kB\u001b[0m \u001b[31m235.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m198.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7.0,>=1.5.10->autogluon.multimodal==0.5.0->autogluon) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m145.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fairscale, antlr4-python3-runtime, gdown, sacremoses, contextvars, future, pymeeus\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307225 sha256=8d46cb85cafb89a59eb51a362160d6f893aabe824f974de295b9680e8e6a5799\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=7644d23ee65adc50f790d00f71097d8cf3a385c61b3365f853e8662e9af438a1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=dda2f497b6b98785f211421d3e2f3db4323d0d43c5c990a98d89927284071602\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=eb47ac976ee7d9a6381bb38565e530bf394cc63b0abcbb5c3915f980a2f1dda6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7664 sha256=737ca58af1129a09fc97ebe5cc3157e215962247784b1683453b1d421f212a8f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=0f55ea30aee544b42ab33cb8949d7590f49f75ecda6812ae544b50db2ce26a3a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for pymeeus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pymeeus: filename=PyMeeus-0.5.11-py3-none-any.whl size=730971 sha256=3fa9c56c6981f337ac89ec4d3f81d58bb98cca7f65c1e1a400e5cdab902e7dda\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ktzur0w4/wheels/33/6b/a6/1d9dae2323750f635654952afc74aa8f2d982cded163f43895\n",
      "Successfully built fairscale antlr4-python3-runtime gdown sacremoses contextvars future pymeeus\n",
      "Installing collected packages: wasabi, typish, tokenizers, tensorboard-plugin-wit, sortedcontainers, sentencepiece, pymeeus, py4j, murmurhash, msgpack, mccabe, korean-lunar-calendar, heapdict, distlib, cymem, antlr4-python3-runtime, zict, yacs, wrapt, tqdm, torch, toolz, tensorboard-data-server, tblib, spacy-loggers, spacy-legacy, soupsieve, smart-open, regex, PySocks, pyrsistent, pyflakes, pyDeprecate, pydantic, pycodestyle, pyasn1-modules, protobuf, preshed, platformdirs, Pillow, omegaconf, oauthlib, numpy, multidict, locket, langcodes, importlib-resources, importlib-metadata, immutables, hijri-converter, grpcio, future, frozenlist, filelock, fastprogress, convertdate, charset-normalizer, catalogue, cachetools, autocfg, asynctest, async-timeout, absl-py, yarl, virtualenv, torchvision, torchmetrics, tifffile, tensorboardX, srsly, scipy, sacrebleu, requests-oauthlib, PyWavelets, patsy, partd, nptyping, markdown, jsonschema, huggingface-hub, holidays, google-auth, flake8, fastcore, fairscale, deprecated, contextvars, click, blis, beautifulsoup4, aiosignal, xgboost, typer, transformers, timm, thinc, statsmodels, scikit-image, sacremoses, ray, nltk, hyperopt, google-auth-oauthlib, gdown, fastdownload, dask, aiohttp, tensorboard, sktime, pytorch-metric-learning, pmdarima, pathy, nlpaug, lightgbm, gluonts, gluoncv, distributed, catboost, autogluon-contrib-nlp, tbats, spacy, pytorch-lightning, autogluon.common, fastai, autogluon.features, autogluon.core, autogluon.vision, autogluon.timeseries, autogluon.tabular, autogluon.multimodal, autogluon.text, autogluon\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.39.0\n",
      "    Uninstalling tqdm-4.39.0:\n",
      "      Successfully uninstalled tqdm-4.39.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "      Successfully uninstalled Pillow-8.4.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.8.2\n",
      "    Uninstalling importlib-metadata-4.8.2:\n",
      "      Successfully uninstalled importlib-metadata-4.8.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: gluoncv\n",
      "    Found existing installation: gluoncv 0.8.0\n",
      "    Uninstalling gluoncv-0.8.0:\n",
      "      Successfully uninstalled gluoncv-0.8.0\n",
      "Successfully installed Pillow-9.0.1 PySocks-1.7.1 PyWavelets-1.3.0 absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.2 asynctest-0.13.0 autocfg-0.0.8 autogluon-0.5.0 autogluon-contrib-nlp-0.0.1b20220208 autogluon.common-0.5.0 autogluon.core-0.5.0 autogluon.features-0.5.0 autogluon.multimodal-0.5.0 autogluon.tabular-0.5.0 autogluon.text-0.5.0 autogluon.timeseries-0.5.0 autogluon.vision-0.5.0 beautifulsoup4-4.11.1 blis-0.7.8 cachetools-5.2.0 catalogue-2.0.7 catboost-1.0.6 charset-normalizer-2.1.0 click-8.0.4 contextvars-2.4 convertdate-2.4.0 cymem-2.0.6 dask-2021.11.2 deprecated-1.2.13 distlib-0.3.5 distributed-2021.11.2 fairscale-0.4.6 fastai-2.5.6 fastcore-1.4.5 fastdownload-0.0.7 fastprogress-1.0.2 filelock-3.7.1 flake8-4.0.1 frozenlist-1.3.0 future-0.18.2 gdown-4.5.1 gluoncv-0.10.5.post0 gluonts-0.10.2 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.43.0 heapdict-1.0.1 hijri-converter-2.2.4 holidays-0.14.2 huggingface-hub-0.8.1 hyperopt-0.2.7 immutables-0.18 importlib-metadata-4.2.0 importlib-resources-5.8.0 jsonschema-4.7.2 korean-lunar-calendar-0.2.1 langcodes-3.3.0 lightgbm-3.3.2 locket-1.0.0 markdown-3.3.4 mccabe-0.6.1 msgpack-1.0.4 multidict-6.0.2 murmurhash-1.0.7 nlpaug-1.1.11 nltk-3.7 nptyping-1.4.4 numpy-1.21.6 oauthlib-3.2.0 omegaconf-2.1.2 partd-1.2.0 pathy-0.6.2 patsy-0.5.2 platformdirs-2.5.2 pmdarima-1.8.5 preshed-3.0.6 protobuf-3.18.1 py4j-0.10.9.5 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pycodestyle-2.8.0 pydantic-1.9.1 pyflakes-2.4.0 pymeeus-0.5.11 pyrsistent-0.18.1 pytorch-lightning-1.6.5 pytorch-metric-learning-1.3.2 ray-1.13.0 regex-2022.7.9 requests-oauthlib-1.3.1 sacrebleu-2.1.0 sacremoses-0.0.53 scikit-image-0.19.3 scipy-1.7.3 sentencepiece-0.1.95 sktime-0.13.0 smart-open-5.2.1 sortedcontainers-2.4.0 soupsieve-2.3.2.post1 spacy-3.4.0 spacy-legacy-3.0.9 spacy-loggers-1.0.3 srsly-2.4.3 statsmodels-0.13.2 tbats-1.1.0 tblib-1.7.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.5.1 thinc-8.1.0 tifffile-2021.11.2 timm-0.5.4 tokenizers-0.12.1 toolz-0.12.0 torch-1.11.0 torchmetrics-0.7.3 torchvision-0.12.0 tqdm-4.64.0 transformers-4.20.1 typer-0.4.2 typish-1.9.3 virtualenv-20.15.1 wasabi-0.9.1 wrapt-1.14.1 xgboost-1.4.2 yacs-0.1.8 yarl-1.7.2 zict-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220715_124920/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220715_124920/\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.7.10\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    4\n",
      "Train Data Columns: 2\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.251 to avoid cutting too many classes.\n",
      "Warning: Updated num_bag_folds from 5 to 4 to avoid cutting too many classes.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2901.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['num', 'amount']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['num', 'amount']\n",
      "\t0.1s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.89s of the 59.88s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsUnif_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tExpected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 220, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 359, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 130, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 140, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = self.model.predict_proba_loo()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/_knn_loo_variants.py\", line 67, in predict_proba_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 726, in kneighbors\n",
      "    \" but n_samples = %d, n_neighbors = %d\" % (n_samples_fit, n_neighbors)\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.82s of the 59.81s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsDist_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tExpected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 220, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 359, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 130, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 140, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = self.model.predict_proba_loo()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/_knn_loo_variants.py\", line 67, in predict_proba_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 726, in kneighbors\n",
      "    \" but n_samples = %d, n_neighbors = %d\" % (n_samples_fit, n_neighbors)\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 59.76s of the 59.75s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:49:22,414\tWARNING services.py:2013 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.93gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\t0.0\t = Validation score   (accuracy)\n",
      "\t5.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 48.26s of the 48.26s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0\t = Validation score   (accuracy)\n",
      "\t5.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 39.61s of the 39.61s of remaining time.\n",
      "\t0.0\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 38.79s of the 38.79s of remaining time.\n",
      "\t0.0\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 37.76s of the 37.75s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.25\t = Validation score   (accuracy)\n",
      "\t4.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 30.68s of the 30.67s of remaining time.\n",
      "\t0.0\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 29.93s of the 29.93s of remaining time.\n",
      "\t0.0\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 28.8s of the 28.79s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.75\t = Validation score   (accuracy)\n",
      "\t12.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 13.42s of the 13.42s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5\t = Validation score   (accuracy)\n",
      "\t3.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 5.75s of the 5.74s of remaining time.\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1102, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 203, in _fit\n",
      "    **fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 349, in _train_net\n",
      "    logger.log(15, f\"Epoch {epoch} (Update {total_updates}).\\t\"\n",
      "ZeroDivisionError: float division by zero\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 234, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 503, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 468, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 436, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1831, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ZeroDivisionError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1102, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 203, in _fit\n",
      "    **fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 349, in _train_net\n",
      "    logger.log(15, f\"Epoch {epoch} (Update {total_updates}).\\t\"\n",
      "ZeroDivisionError: float division by zero\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.89s of the -1.11s of remaining time.\n",
      "\t0.75\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 61.53s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220715_124920/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   NeuralNetFastAI_BAG_L1       0.75       0.080221  12.778297                0.080221          12.778297            1       True          8\n",
      "1      WeightedEnsemble_L2       0.75       0.080655  13.003955                0.000434           0.225657            2       True         10\n",
      "2           XGBoost_BAG_L1       0.50       0.022637   3.870177                0.022637           3.870177            1       True          9\n",
      "3          CatBoost_BAG_L1       0.25       0.002646   4.416053                0.002646           4.416053            1       True          5\n",
      "4          LightGBM_BAG_L1       0.00       0.008999   5.576468                0.008999           5.576468            1       True          2\n",
      "5        LightGBMXT_BAG_L1       0.00       0.009418   5.828673                0.009418           5.828673            1       True          1\n",
      "6  RandomForestGini_BAG_L1       0.00       0.093312   0.604673                0.093312           0.604673            1       True          3\n",
      "7    ExtraTreesGini_BAG_L1       0.00       0.093857   0.528740                0.093857           0.528740            1       True          6\n",
      "8    ExtraTreesEntr_BAG_L1       0.00       0.094405   0.916702                0.094405           0.916702            1       True          7\n",
      "9  RandomForestEntr_BAG_L1       0.00       0.162838   0.749705                0.162838           0.749705            1       True          4\n",
      "Number of models trained: 10\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 4 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('int', []) : 2 | ['num', 'amount']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20220715_124920/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.75\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.75,\n",
      "    \"balanced_accuracy\": 0.75,\n",
      "    \"mcc\": 0.5773502691896258,\n",
      "    \"roc_auc\": 0.75,\n",
      "    \"f1\": 0.6666666666666666,\n",
      "    \"precision\": 1.0,\n",
      "    \"recall\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]],\n",
    "    columns=[\"num\", \"amount\", \"target\"]\n",
    ")\n",
    "\n",
    "predictor = TabularPredictor(label=\"target\").fit(\n",
    "    train_data=df,\n",
    "    time_limit=60,\n",
    "    presets=\"best_quality\"\n",
    ")\n",
    "\n",
    "# output a summary of created models\n",
    "predictor.fit_summary()\n",
    "\n",
    "# evaluate best model from hyperparameter search\n",
    "performance = predictor.evaluate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220715_125023/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220715_125023/\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.7.10\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    3\n",
      "Train Data Columns: 2\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Updated label_count_threshold from 10 to 1 to avoid cutting too many classes.\n",
      "Warning: Updated holdout_frac from 0.2 to 0.3343333333333333 to avoid cutting too many classes.\n",
      "Warning: Updated num_bag_folds from 5 to 3 to avoid cutting too many classes.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2818.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['num', 'amount']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['num', 'amount']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.91s of the 119.9s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsUnif_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tExpected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 220, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 359, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 130, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 140, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = self.model.predict_proba_loo()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/_knn_loo_variants.py\", line 67, in predict_proba_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 726, in kneighbors\n",
      "    \" but n_samples = %d, n_neighbors = %d\" % (n_samples_fit, n_neighbors)\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.84s of the 119.84s of remaining time.\n",
      "\tWarning: Exception caused KNeighborsDist_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tExpected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 220, in _fit\n",
      "    self._fit_single(X=X, y=y, model_base=model_base, use_child_oof=use_child_oof, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 359, in _fit_single\n",
      "    self._oof_pred_proba = model_base.get_oof_pred_proba(X=X, y=y)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 130, in get_oof_pred_proba\n",
      "    y_oof_pred_proba = self._get_oof_pred_proba(X=X, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/knn_model.py\", line 140, in _get_oof_pred_proba\n",
      "    y_oof_pred_proba = self.model.predict_proba_loo()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/knn/_knn_loo_variants.py\", line 67, in predict_proba_loo\n",
      "    neigh_dist, neigh_ind = self.kneighbors()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sklearn/neighbors/_base.py\", line 726, in kneighbors\n",
      "    \" but n_samples = %d, n_neighbors = %d\" % (n_samples_fit, n_neighbors)\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 119.78s of the 119.78s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:50:26,522\tWARNING services.py:2013 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t4.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 109.6s of the 109.59s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t4.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 102.66s of the 102.66s of remaining time.\n",
      "\t0.3333\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 101.92s of the 101.92s of remaining time.\n",
      "\t0.3333\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 100.99s of the 100.99s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:50:48,520\tERROR serialization.py:342 -- Failed to unpickle serialized exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 38, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/serialization.py\", line 340, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/serialization.py\", line 260, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 32, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 41, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tSystem error: Failed to unpickle serialized exception\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 38, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/serialization.py\", line 340, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/serialization.py\", line 260, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 32, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 41, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 234, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 503, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 468, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 436, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1833, in get\n",
      "    raise value\n",
      "ray.exceptions.RaySystemError: System error: Failed to unpickle serialized exception\n",
      "traceback: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 38, in from_ray_exception\n",
      "    return pickle.loads(ray_exception.serialized_exception)\n",
      "ModuleNotFoundError: No module named '_catboost'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/serialization.py\", line 340, in deserialize_objects\n",
      "    obj = self._deserialize_object(data, metadata, object_ref)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/serialization.py\", line 260, in _deserialize_object\n",
      "    return RayError.from_bytes(obj)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 32, in from_bytes\n",
      "    return RayError.from_ray_exception(ray_exception)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/exceptions.py\", line 41, in from_ray_exception\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Failed to unpickle serialized exception\n",
      "\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 92.56s of the 92.55s of remaining time.\n",
      "\t0.3333\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 91.68s of the 91.67s of remaining time.\n",
      "\t0.3333\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 90.94s of the 90.94s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:50:55,910\tWARNING services.py:2013 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1830, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 284, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params['lr'], cbs=callbacks)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/callback/schedule.py\", line 116, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 221, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 212, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 207, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 203, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 169, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 194, in one_batch\n",
      "    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 175, in _do_one_batch\n",
      "    self.loss_grad = self.loss_func(self.pred, *self.yb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/losses.py\", line 35, in __call__\n",
      "    return self.func.__call__(inp, targ.view(-1) if self.flatten else targ, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 1165, in forward\n",
      "    label_smoothing=self.label_smoothing)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\", line 2992, in cross_entropy\n",
      "    label_smoothing=label_smoothing,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/overrides.py\", line 1394, in handle_torch_function\n",
      "    result = torch_func_method(public_api, types, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/torch_core.py\", line 341, in __torch_function__\n",
      "    res = super().__torch_function__(func, types, args=args, kwargs=kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/_tensor.py\", line 1142, in __torch_function__\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\", line 2996, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target -1 is out of bounds.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 234, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 503, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 468, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 436, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1831, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(IndexError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1830, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 284, in _fit\n",
      "    self.model.fit_one_cycle(epochs, params['lr'], cbs=callbacks)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/callback/schedule.py\", line 116, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 221, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 212, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 207, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 203, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 169, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 194, in one_batch\n",
      "    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/learner.py\", line 175, in _do_one_batch\n",
      "    self.loss_grad = self.loss_func(self.pred, *self.yb)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/losses.py\", line 35, in __call__\n",
      "    return self.func.__call__(inp, targ.view(-1) if self.flatten else targ, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 1165, in forward\n",
      "    label_smoothing=self.label_smoothing)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\", line 2992, in cross_entropy\n",
      "    label_smoothing=label_smoothing,\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/overrides.py\", line 1394, in handle_torch_function\n",
      "    result = torch_func_method(public_api, types, args, kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/fastai/torch_core.py\", line 341, in __torch_function__\n",
      "    res = super().__torch_function__(func, types, args=args, kwargs=kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/_tensor.py\", line 1142, in __torch_function__\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\", line 2996, in cross_entropy\n",
      "    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
      "IndexError: Target -1 is out of bounds.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 74.31s of the 74.3s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:51:12,172\tWARNING services.py:2013 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2050, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 143, in _fit\n",
      "    sample_weight=sample_weight\n",
      "  File \"/usr/local/lib/python3.7/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 234, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 503, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 468, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 436, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1831, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2050, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 143, in _fit\n",
      "    sample_weight=sample_weight\n",
      "  File \"/usr/local/lib/python3.7/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 62.96s of the 62.95s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:51:23,556\tWARNING services.py:2013 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2187, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 203, in _fit\n",
      "    **fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 349, in _train_net\n",
      "    logger.log(15, f\"Epoch {epoch} (Update {total_updates}).\\t\"\n",
      "ZeroDivisionError: float division by zero\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1086, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1044, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 234, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 503, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 468, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 436, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1831, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ZeroDivisionError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2187, ip=169.255.254.2)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 290, in _ray_fit\n",
      "    time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 579, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 203, in _fit\n",
      "    **fit_kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 349, in _train_net\n",
      "    logger.log(15, f\"Epoch {epoch} (Update {total_updates}).\\t\"\n",
      "ZeroDivisionError: float division by zero\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 53.27s of the 53.26s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-07-15 12:51:33,021\tWARNING services.py:2013 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.91gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.91s of the 43.0s of remaining time.\n",
      "\t0.6667\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 77.36s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220715_125023/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a classifier, autogluon will pick it up\n",
    "predictor = TabularPredictor(label = 'target').fit(train_data = df_train, time_limit =120, presets ='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     LightGBMLarge_BAG_L1   0.666667       0.006762  4.191194                0.006762           4.191194            1       True          7\n",
      "1          LightGBM_BAG_L1   0.666667       0.006943  4.181633                0.006943           4.181633            1       True          2\n",
      "2        LightGBMXT_BAG_L1   0.666667       0.007333  4.115733                0.007333           4.115733            1       True          1\n",
      "3      WeightedEnsemble_L2   0.666667       0.007757  4.303950                0.000424           0.188217            2       True          8\n",
      "4    ExtraTreesGini_BAG_L1   0.333333       0.090975  0.663968                0.090975           0.663968            1       True          5\n",
      "5  RandomForestEntr_BAG_L1   0.333333       0.091254  0.715817                0.091254           0.715817            1       True          4\n",
      "6  RandomForestGini_BAG_L1   0.333333       0.093745  0.524745                0.093745           0.524745            1       True          3\n",
      "7    ExtraTreesEntr_BAG_L1   0.333333       0.093824  0.521679                0.093824           0.521679            1       True          6\n",
      "Number of models trained: 8\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 3 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('int', []) : 2 | ['num', 'amount']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20220715_125023/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 0.6666666666666666,\n",
       "  'LightGBM_BAG_L1': 0.6666666666666666,\n",
       "  'RandomForestGini_BAG_L1': 0.3333333333333333,\n",
       "  'RandomForestEntr_BAG_L1': 0.3333333333333333,\n",
       "  'ExtraTreesGini_BAG_L1': 0.3333333333333333,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.3333333333333333,\n",
       "  'LightGBMLarge_BAG_L1': 0.6666666666666666,\n",
       "  'WeightedEnsemble_L2': 0.6666666666666666},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestGini_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/RandomForestGini_BAG_L1/',\n",
       "  'RandomForestEntr_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/RandomForestEntr_BAG_L1/',\n",
       "  'ExtraTreesGini_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/ExtraTreesGini_BAG_L1/',\n",
       "  'ExtraTreesEntr_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/ExtraTreesEntr_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20220715_125023/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20220715_125023/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 4.115732908248901,\n",
       "  'LightGBM_BAG_L1': 4.1816325187683105,\n",
       "  'RandomForestGini_BAG_L1': 0.5247447490692139,\n",
       "  'RandomForestEntr_BAG_L1': 0.7158174514770508,\n",
       "  'ExtraTreesGini_BAG_L1': 0.6639680862426758,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.5216789245605469,\n",
       "  'LightGBMLarge_BAG_L1': 4.191194295883179,\n",
       "  'WeightedEnsemble_L2': 0.1882171630859375},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 0.007332801818847656,\n",
       "  'LightGBM_BAG_L1': 0.0069429874420166016,\n",
       "  'RandomForestGini_BAG_L1': 0.09374499320983887,\n",
       "  'RandomForestEntr_BAG_L1': 0.09125423431396484,\n",
       "  'ExtraTreesGini_BAG_L1': 0.09097528457641602,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.09382367134094238,\n",
       "  'LightGBMLarge_BAG_L1': 0.0067615509033203125,\n",
       "  'WeightedEnsemble_L2': 0.0004239082336425781},\n",
       " 'num_bag_folds': 3,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                      model  score_val  pred_time_val  fit_time  \\\n",
       " 0     LightGBMLarge_BAG_L1   0.666667       0.006762  4.191194   \n",
       " 1          LightGBM_BAG_L1   0.666667       0.006943  4.181633   \n",
       " 2        LightGBMXT_BAG_L1   0.666667       0.007333  4.115733   \n",
       " 3      WeightedEnsemble_L2   0.666667       0.007757  4.303950   \n",
       " 4    ExtraTreesGini_BAG_L1   0.333333       0.090975  0.663968   \n",
       " 5  RandomForestEntr_BAG_L1   0.333333       0.091254  0.715817   \n",
       " 6  RandomForestGini_BAG_L1   0.333333       0.093745  0.524745   \n",
       " 7    ExtraTreesEntr_BAG_L1   0.333333       0.093824  0.521679   \n",
       " \n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                0.006762           4.191194            1       True   \n",
       " 1                0.006943           4.181633            1       True   \n",
       " 2                0.007333           4.115733            1       True   \n",
       " 3                0.000424           0.188217            2       True   \n",
       " 4                0.090975           0.663968            1       True   \n",
       " 5                0.091254           0.715817            1       True   \n",
       " 6                0.093745           0.524745            1       True   \n",
       " 7                0.093824           0.521679            1       True   \n",
       " \n",
       "    fit_order  \n",
       " 0          7  \n",
       " 1          2  \n",
       " 2          1  \n",
       " 3          8  \n",
       " 4          5  \n",
       " 5          4  \n",
       " 6          3  \n",
       " 7          6  }"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output the model's `score_val` in a bar chart to compare performance\n",
    "predictor.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-07b8e99aa281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the models performance on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data, model, silent, auxiliary_metrics, detailed_report)\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         return self.evaluate_predictions(y_true=data[self.label], y_pred=y_pred_proba, sample_weight=sample_weight, silent=silent,\n\u001b[0;32m-> 1450\u001b[0;31m                                          auxiliary_metrics=auxiliary_metrics, detailed_report=detailed_report)\n\u001b[0m\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauxiliary_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_report\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mevaluate_predictions\u001b[0;34m(self, y_true, y_pred, sample_weight, silent, auxiliary_metrics, detailed_report)\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \"\"\"\n\u001b[1;32m   1480\u001b[0m         return self._learner.evaluate_predictions(y_true=y_true, y_pred=y_pred, sample_weight=sample_weight, silent=silent,\n\u001b[0;32m-> 1481\u001b[0;31m                                                   auxiliary_metrics=auxiliary_metrics, detailed_report=detailed_report)\n\u001b[0m\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mleaderboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_pareto_frontier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mevaluate_predictions\u001b[0;34m(self, y_true, y_pred, sample_weight, silent, auxiliary_metrics, detailed_report)\u001b[0m\n\u001b[1;32m    568\u001b[0m                         \u001b[0my_pred_proba_internal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred_proba_internal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maux_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                         \u001b[0;34m**\u001b[0m\u001b[0mscoring_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     )\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36m_score_with_pred_proba\u001b[0;34m(self, y, y_internal, y_pred_proba_internal, metric, sample_weight, weight_evaluation)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_cleaner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba_internal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0my_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_internal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_weighted_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_evaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantile_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     def _score_with_pred(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/core/utils/utils.py\u001b[0m in \u001b[0;36mcompute_weighted_metric\u001b[0;34m(y, y_pred, metric, weights, weight_evaluation, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample weights cannot be None when weight_evaluation=True.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mweight_evaluation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mweighted_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/autogluon/core/metrics/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         )\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         raise ValueError(\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"is not defined in that case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes =  datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "dfd = pd.DataFrame(diabetes['data'], columns=diabetes['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "dfd['target'] = diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220715_125640/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220715_125640/\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.7.10\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    353\n",
      "Train Data Columns: 10\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2542.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['age', 'sex', 'bmi', 'bp', 's1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.9s of the 119.89s of remaining time.\n",
      "\t0.4305\t = Validation score   (r2)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.65s of the 119.64s of remaining time.\n",
      "\t0.4397\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 119.44s of the 119.44s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5416\t = Validation score   (r2)\n",
      "\t9.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 107.28s of the 107.28s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.514\t = Validation score   (r2)\n",
      "\t9.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 95.13s of the 95.13s of remaining time.\n",
      "\t0.4706\t = Validation score   (r2)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 94.02s of the 94.02s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5228\t = Validation score   (r2)\n",
      "\t9.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 81.82s of the 81.81s of remaining time.\n",
      "\t0.4967\t = Validation score   (r2)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 80.76s of the 80.76s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4904\t = Validation score   (r2)\n",
      "\t15.74s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 61.88s of the 61.87s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4456\t = Validation score   (r2)\n",
      "\t8.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 50.69s of the 50.68s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5219\t = Validation score   (r2)\n",
      "\t13.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 34.81s of the 34.81s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4569\t = Validation score   (r2)\n",
      "\t10.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.9s of the 21.51s of remaining time.\n",
      "\t0.5525\t = Validation score   (r2)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 99.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220715_125640/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a regression, autogluon will pick it up\n",
    "predictor = TabularPredictor(label = 'target', problem_type=\"regression\", eval_metric=\"r2\").fit(train_data = dfd_train, time_limit =120, presets ='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L2   0.552480       0.166335  48.352685                0.000723           0.515819            2       True         12\n",
      "1        LightGBMXT_BAG_L1   0.541581       0.017544   9.529923                0.017544           9.529923            1       True          3\n",
      "2          CatBoost_BAG_L1   0.522807       0.012066   9.650069                0.012066           9.650069            1       True          6\n",
      "3    NeuralNetTorch_BAG_L1   0.521945       0.034628  13.185131                0.034628          13.185131            1       True         10\n",
      "4          LightGBM_BAG_L1   0.514039       0.016049   9.379414                0.016049           9.379414            1       True          4\n",
      "5     ExtraTreesMSE_BAG_L1   0.496684       0.185295   0.624823                0.185295           0.624823            1       True          7\n",
      "6   NeuralNetFastAI_BAG_L1   0.490437       0.097391  15.742398                0.097391          15.742398            1       True          8\n",
      "7   RandomForestMSE_BAG_L1   0.470609       0.158766   0.722375                0.158766           0.722375            1       True          5\n",
      "8     LightGBMLarge_BAG_L1   0.456922       0.017849  10.517482                0.017849          10.517482            1       True         11\n",
      "9           XGBoost_BAG_L1   0.445574       0.032216   8.118636                0.032216           8.118636            1       True          9\n",
      "10   KNeighborsDist_BAG_L1   0.439701       0.102018   0.008852                0.102018           0.008852            1       True          2\n",
      "11   KNeighborsUnif_BAG_L1   0.430521       0.106901   0.016948                0.106901           0.016948            1       True          1\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20220715_125640/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.43052099899418794,\n",
       "  'KNeighborsDist_BAG_L1': 0.43970122394744415,\n",
       "  'LightGBMXT_BAG_L1': 0.5415805668677733,\n",
       "  'LightGBM_BAG_L1': 0.5140394842930078,\n",
       "  'RandomForestMSE_BAG_L1': 0.4706085411454686,\n",
       "  'CatBoost_BAG_L1': 0.5228072001429453,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.4966838407427535,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.49043661409631567,\n",
       "  'XGBoost_BAG_L1': 0.4455738728434837,\n",
       "  'NeuralNetTorch_BAG_L1': 0.5219454545622099,\n",
       "  'LightGBMLarge_BAG_L1': 0.45692155144090785,\n",
       "  'WeightedEnsemble_L2': 0.5524795451208633},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/KNeighborsDist_BAG_L1/',\n",
       "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/RandomForestMSE_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/ExtraTreesMSE_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetTorch_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/NeuralNetTorch_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20220715_125640/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20220715_125640/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.016948223114013672,\n",
       "  'KNeighborsDist_BAG_L1': 0.00885152816772461,\n",
       "  'LightGBMXT_BAG_L1': 9.529923439025879,\n",
       "  'LightGBM_BAG_L1': 9.379414319992065,\n",
       "  'RandomForestMSE_BAG_L1': 0.7223749160766602,\n",
       "  'CatBoost_BAG_L1': 9.650068998336792,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.6248228549957275,\n",
       "  'NeuralNetFastAI_BAG_L1': 15.742397785186768,\n",
       "  'XGBoost_BAG_L1': 8.1186363697052,\n",
       "  'NeuralNetTorch_BAG_L1': 13.185130834579468,\n",
       "  'LightGBMLarge_BAG_L1': 10.517482280731201,\n",
       "  'WeightedEnsemble_L2': 0.5158185958862305},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.10690069198608398,\n",
       "  'KNeighborsDist_BAG_L1': 0.10201787948608398,\n",
       "  'LightGBMXT_BAG_L1': 0.017543554306030273,\n",
       "  'LightGBM_BAG_L1': 0.01604914665222168,\n",
       "  'RandomForestMSE_BAG_L1': 0.1587662696838379,\n",
       "  'CatBoost_BAG_L1': 0.012066364288330078,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.18529510498046875,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.09739089012145996,\n",
       "  'XGBoost_BAG_L1': 0.03221607208251953,\n",
       "  'NeuralNetTorch_BAG_L1': 0.03462815284729004,\n",
       "  'LightGBMLarge_BAG_L1': 0.017849445343017578,\n",
       "  'WeightedEnsemble_L2': 0.0007231235504150391},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                      model  score_val  pred_time_val   fit_time  \\\n",
       " 0      WeightedEnsemble_L2   0.552480       0.166335  48.352685   \n",
       " 1        LightGBMXT_BAG_L1   0.541581       0.017544   9.529923   \n",
       " 2          CatBoost_BAG_L1   0.522807       0.012066   9.650069   \n",
       " 3    NeuralNetTorch_BAG_L1   0.521945       0.034628  13.185131   \n",
       " 4          LightGBM_BAG_L1   0.514039       0.016049   9.379414   \n",
       " 5     ExtraTreesMSE_BAG_L1   0.496684       0.185295   0.624823   \n",
       " 6   NeuralNetFastAI_BAG_L1   0.490437       0.097391  15.742398   \n",
       " 7   RandomForestMSE_BAG_L1   0.470609       0.158766   0.722375   \n",
       " 8     LightGBMLarge_BAG_L1   0.456922       0.017849  10.517482   \n",
       " 9           XGBoost_BAG_L1   0.445574       0.032216   8.118636   \n",
       " 10   KNeighborsDist_BAG_L1   0.439701       0.102018   0.008852   \n",
       " 11   KNeighborsUnif_BAG_L1   0.430521       0.106901   0.016948   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.000723           0.515819            2       True   \n",
       " 1                 0.017544           9.529923            1       True   \n",
       " 2                 0.012066           9.650069            1       True   \n",
       " 3                 0.034628          13.185131            1       True   \n",
       " 4                 0.016049           9.379414            1       True   \n",
       " 5                 0.185295           0.624823            1       True   \n",
       " 6                 0.097391          15.742398            1       True   \n",
       " 7                 0.158766           0.722375            1       True   \n",
       " 8                 0.017849          10.517482            1       True   \n",
       " 9                 0.032216           8.118636            1       True   \n",
       " 10                0.102018           0.008852            1       True   \n",
       " 11                0.106901           0.016948            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0          12  \n",
       " 1           3  \n",
       " 2           6  \n",
       " 3          10  \n",
       " 4           4  \n",
       " 5           7  \n",
       " 6           8  \n",
       " 7           5  \n",
       " 8          11  \n",
       " 9           9  \n",
       " 10          2  \n",
       " 11          1  }"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: r2 on test data: 0.31066540132959464\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"r2\": 0.31066540132959464,\n",
      "    \"root_mean_squared_error\": -59.45466778002584,\n",
      "    \"mean_squared_error\": -3534.8575208332427,\n",
      "    \"mean_absolute_error\": -44.637027869063814,\n",
      "    \"pearsonr\": 0.5863545024881145,\n",
      "    \"median_absolute_error\": -32.84114074707031\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(dfd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/mxnet-1.8-cpu-py37-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
